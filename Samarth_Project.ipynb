{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext.getOrCreate()\n",
    "# initializing spark session\n",
    "spark = SparkSession(sc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Set the schema for all the data sets and load them from different locations using file structured streaming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, FloatType, LongType, IntegerType, DateType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schemas for each data set\n",
    "cust_dimen_schema = StructType([\n",
    "    StructField(\"Customer_Name\", StringType()),\n",
    "    StructField(\"Province\", StringType()),\n",
    "    StructField(\"Region\", StringType()),\n",
    "    StructField(\"Customer_Segment\", StringType()),\n",
    "    StructField(\"Cust_id\", StringType())\n",
    "])\n",
    "\n",
    "\n",
    "market_fact_schema = StructType([\n",
    "    StructField(\"Ord_id\", StringType()),\n",
    "    StructField(\"Prod_id\", StringType()),\n",
    "    StructField(\"Ship_id\", StringType()),\n",
    "    StructField(\"Cust_id\", StringType()),\n",
    "    StructField(\"Sales\", DoubleType()),\n",
    "    StructField(\"Discount\", DoubleType()),\n",
    "    StructField(\"Order_Quantity\",IntegerType()),\n",
    "    StructField(\"Profit\", DoubleType()),\n",
    "    StructField(\"Shipping_Cost\", DoubleType()),\n",
    "    StructField(\"Product_Base_Margin\", DoubleType())\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "orders_dimen_schema = StructType([\n",
    "    StructField(\"Order_ID\", StringType()),\n",
    "    StructField(\"Order_Date\", DateType()),\n",
    "    StructField(\"Order_Priority\", StringType()),\n",
    "    StructField(\"Ord_id\", StringType())\n",
    "])\n",
    "\n",
    "\n",
    "prod_dimen_schema = StructType([\n",
    "    StructField(\"Product_Category\", StringType()),\n",
    "    StructField(\"Product_Sub_Category\", StringType()),\n",
    "    StructField(\"Prod_id\", StringType())\n",
    "])\n",
    "\n",
    "shipping_dimen_schema = StructType([\n",
    "    StructField(\"Order_ID\", StringType()),\n",
    "    StructField(\"Ship_Mode\", StringType()),\n",
    "    StructField(\"Ship_Date\", DateType()),\n",
    "    StructField(\"Ship_id\", StringType())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using file structured streaming\n",
    "#= spark.readStream \\\n",
    "#    .schema() \\\n",
    " #   .csv(\"/ user/ samarthpu42wgre/ \")\n",
    "cust_dimen_df = spark.read.format(\"csv\").option(\"header\", \"true\").schema(cust_dimen_schema).load(\"cust_dimen.csv\")\n",
    "market_fact_df = spark.read.format(\"csv\").option(\"header\", \"true\").schema(market_fact_schema).load(\"market_fact.csv\")\n",
    "orders_dimen_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"dateFormat\",\"dd-mm-yyyy\").schema(orders_dimen_schema).load(\"orders_dimen.csv\")\n",
    "prod_dimen_df = spark.read.format(\"csv\").option(\"header\", \"true\").schema(prod_dimen_schema).load(\"prod_dimen.csv\")\n",
    "shipping_dimen_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"dateFormat\",\"dd-mm-yyyy\").schema(shipping_dimen_schema).load(\"shipping_dimen.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+-------+----------------+-------+\n",
      "|     Customer_Name|Province| Region|Customer_Segment|Cust_id|\n",
      "+------------------+--------+-------+----------------+-------+\n",
      "|MUHAMMED MACINTYRE| NUNAVUT|NUNAVUT|  SMALL BUSINESS| Cust_1|\n",
      "|      BARRY FRENCH| NUNAVUT|NUNAVUT|        CONSUMER| Cust_2|\n",
      "+------------------+--------+-------+----------------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_dimen_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+-------+----------------+-------+\n",
      "|Customer_Name     |Province|Region |Customer_Segment|Cust_id|\n",
      "+------------------+--------+-------+----------------+-------+\n",
      "|MUHAMMED MACINTYRE|NUNAVUT |NUNAVUT|SMALL BUSINESS  |Cust_1 |\n",
      "|BARRY FRENCH      |NUNAVUT |NUNAVUT|CONSUMER        |Cust_2 |\n",
      "|CLAY ROZENDAL     |NUNAVUT |NUNAVUT|CORPORATE       |Cust_3 |\n",
      "|CARLOS SOLTERO    |NUNAVUT |NUNAVUT|CONSUMER        |Cust_4 |\n",
      "+------------------+--------+-------+----------------+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_dimen_df.select(\"*\").show(4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+---------+------+--------+--------------+------+-------------+-------------------+\n",
      "|  Ord_id|Prod_id| Ship_id|  Cust_id| Sales|Discount|Order_Quantity|Profit|Shipping_Cost|Product_Base_Margin|\n",
      "+--------+-------+--------+---------+------+--------+--------------+------+-------------+-------------------+\n",
      "|Ord_5446|Prod_16|SHP_7609|Cust_1818|136.81|    0.01|            23|-30.51|          3.6|               0.56|\n",
      "|Ord_5406|Prod_13|SHP_7549|Cust_1818| 42.27|    0.01|            13|  4.56|         0.93|               0.54|\n",
      "+--------+-------+--------+---------+------+--------+--------------+------+-------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "market_fact_df.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------+------+\n",
      "|Order_ID|Order_Date|Order_Priority|Ord_id|\n",
      "+--------+----------+--------------+------+\n",
      "|       3|2010-01-13|           LOW| Ord_1|\n",
      "|     293|2012-01-01|          HIGH| Ord_2|\n",
      "+--------+----------+--------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_dimen_df.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-------+\n",
      "|Product_Category|Product_Sub_Category|Prod_id|\n",
      "+----------------+--------------------+-------+\n",
      "| OFFICE SUPPLIES|STORAGE & ORGANIZ...| Prod_1|\n",
      "| OFFICE SUPPLIES|          APPLIANCES| Prod_2|\n",
      "+----------------+--------------------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prod_dimen_df.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+----------+-------+\n",
      "|Order_ID|     Ship_Mode| Ship_Date|Ship_id|\n",
      "+--------+--------------+----------+-------+\n",
      "|       3|   REGULAR AIR|2010-01-20|  SHP_1|\n",
      "|     293|DELIVERY TRUCK|2012-01-02|  SHP_2|\n",
      "+--------+--------------+----------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shipping_dimen_df.show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Join all the Data frames and create a new Data frame called Full_DataFrame in such a way that the new data frame does not contain duplicate columns.\n",
    "(cust_dimen, market_fact, orders_dimen, prod_dimen, shipping_dimen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename duplicate columns\n",
    "market_fact_df = market_fact_df.withColumnRenamed(\"Cust_id\", \"market_customer_id\")\n",
    "market_fact_df = market_fact_df.withColumnRenamed(\"Prod_id\", \"market_product_id\")\n",
    "market_fact_df = market_fact_df.withColumnRenamed(\"Ship_id\", \"market_ship_id\")\n",
    "market_fact_df = market_fact_df.withColumnRenamed(\"Ord_id\", \"market_ord_id\")\n",
    "orders_dimen_df = orders_dimen_df.withColumnRenamed(\"Order_id\", \"orders_order_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_DataFrame = market_fact_df.join(cust_dimen_df, cust_dimen_df.Cust_id == market_fact_df.market_customer_id, \"inner\") \\\n",
    "    .join(orders_dimen_df, market_fact_df.market_ord_id == orders_dimen_df.Ord_id, \"inner\") \\\n",
    "    .join(prod_dimen_df, market_fact_df.market_product_id == prod_dimen_df.Prod_id, \"inner\") \\\n",
    "    .join(shipping_dimen_df, market_fact_df.market_ship_id == shipping_dimen_df.Ship_id, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate columns\n",
    "Full_DataFrame = Full_DataFrame.drop(\"market_customer_id\", \"market_product_id\", \"market_ship_id\", \"market_ord_id\",\"orders_order_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sales: double (nullable = true)\n",
      " |-- Discount: double (nullable = true)\n",
      " |-- Order_Quantity: integer (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      " |-- Shipping_Cost: double (nullable = true)\n",
      " |-- Product_Base_Margin: double (nullable = true)\n",
      " |-- Customer_Name: string (nullable = true)\n",
      " |-- Province: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Customer_Segment: string (nullable = true)\n",
      " |-- Cust_id: string (nullable = true)\n",
      " |-- Order_Date: date (nullable = true)\n",
      " |-- Order_Priority: string (nullable = true)\n",
      " |-- Ord_id: string (nullable = true)\n",
      " |-- Product_Category: string (nullable = true)\n",
      " |-- Product_Sub_Category: string (nullable = true)\n",
      " |-- Prod_id: string (nullable = true)\n",
      " |-- Order_ID: string (nullable = true)\n",
      " |-- Ship_Mode: string (nullable = true)\n",
      " |-- Ship_Date: date (nullable = true)\n",
      " |-- Ship_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Full_DataFrame.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------+------+-------------+-------------------+-------------+--------+------+----------------+---------+----------+--------------+--------+----------------+-----------------------------+-------+--------+-----------+----------+--------+\n",
      "|Sales  |Discount|Order_Quantity|Profit|Shipping_Cost|Product_Base_Margin|Customer_Name|Province|Region|Customer_Segment|Cust_id  |Order_Date|Order_Priority|Ord_id  |Product_Category|Product_Sub_Category         |Prod_id|Order_ID|Ship_Mode  |Ship_Date |Ship_id |\n",
      "+-------+--------+--------------+------+-------------+-------------------+-------------+--------+------+----------------+---------+----------+--------------+--------+----------------+-----------------------------+-------+--------+-----------+----------+--------+\n",
      "|136.81 |0.01    |23            |-30.51|3.6          |0.56               |AARON BERGMAN|ALBERTA |WEST  |CORPORATE       |Cust_1818|2010-01-27|NOT SPECIFIED |Ord_5446|OFFICE SUPPLIES |SCISSORS, RULERS AND TRIMMERS|Prod_16|36262   |REGULAR AIR|2010-01-28|SHP_7609|\n",
      "|42.27  |0.01    |13            |4.56  |0.93         |0.54               |AARON BERGMAN|ALBERTA |WEST  |CORPORATE       |Cust_1818|2009-01-07|HIGH          |Ord_5406|OFFICE SUPPLIES |PENS & ART SUPPLIES          |Prod_13|20513   |EXPRESS AIR|2009-01-08|SHP_7549|\n",
      "|4701.69|0.0     |26            |1148.9|2.5          |0.59               |AARON BERGMAN|ALBERTA |WEST  |CORPORATE       |Cust_1818|2010-01-27|NOT SPECIFIED |Ord_5446|TECHNOLOGY      |TELEPHONES AND COMMUNICATION |Prod_4 |36262   |EXPRESS AIR|2010-01-27|SHP_7610|\n",
      "+-------+--------+--------------+------+-------------+-------------------+-------------+--------+------+----------------+---------+----------+--------------+--------+----------------+-----------------------------+-------+--------+-----------+----------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Full_DataFrame.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Convert the Order_Date and Ship_Date columns type into Date type. And print the schema and show the top 5 records for Order_Date and Ship_Date columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Order_Date and Ship_Date columns to DateType\n",
    "Full_DataFrame = Full_DataFrame.withColumn(\"Order_Date\",Full_DataFrame[\"Order_Date\"].cast(DateType()))\n",
    "Full_DataFrame = Full_DataFrame.withColumn(\"Ship_Date\",Full_DataFrame[\"Ship_Date\"].cast(DateType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema after converting Order_Date and Ship_Date columns:\n",
      "root\n",
      " |-- Sales: double (nullable = true)\n",
      " |-- Discount: double (nullable = true)\n",
      " |-- Order_Quantity: integer (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      " |-- Shipping_Cost: double (nullable = true)\n",
      " |-- Product_Base_Margin: double (nullable = true)\n",
      " |-- Customer_Name: string (nullable = true)\n",
      " |-- Province: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Customer_Segment: string (nullable = true)\n",
      " |-- Cust_id: string (nullable = true)\n",
      " |-- Order_Date: date (nullable = true)\n",
      " |-- Order_Priority: string (nullable = true)\n",
      " |-- Ord_id: string (nullable = true)\n",
      " |-- Product_Category: string (nullable = true)\n",
      " |-- Product_Sub_Category: string (nullable = true)\n",
      " |-- Prod_id: string (nullable = true)\n",
      " |-- Order_ID: string (nullable = true)\n",
      " |-- Ship_Mode: string (nullable = true)\n",
      " |-- Ship_Date: date (nullable = true)\n",
      " |-- Ship_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Schema after converting Order_Date and Ship_Date columns:\")\n",
    "Full_DataFrame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 records for Order_Date and Ship_Date columns:\n",
      "+----------+----------+\n",
      "|Order_Date| Ship_Date|\n",
      "+----------+----------+\n",
      "|2010-01-27|2010-01-28|\n",
      "|2009-01-07|2009-01-08|\n",
      "|2010-01-27|2010-01-27|\n",
      "|2010-01-09|2010-01-11|\n",
      "|2009-01-01|2009-01-08|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show top 5 records for Order_Date and Ship_Date columns\n",
    "print(\"Top 5 records for Order_Date and Ship_Date columns:\")\n",
    "Full_DataFrame.select(\"Order_Date\", \"Ship_Date\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Find the top 3 customers who have the maximum number of orders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only a few columns\n",
    "from pyspark.sql.functions import col, column\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|Cust_id  |Count|\n",
      "+---------+-----+\n",
      "|Cust_1140|17   |\n",
      "|Cust_576 |16   |\n",
      "|Cust_999 |15   |\n",
      "+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Full_DataFrame.groupBy(F.col(\"Cust_id\")).agg(F.countDistinct(\"Ord_id\").alias(\"Count\")).orderBy(F.desc(\"Count\")).show(3,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create a new column DaysTakenForDelivery that contains the date difference between Order_Date and Ship_Date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Full_DataFrame =  Full_DataFrame.withColumn(\"DaysTakenForDelivery\",F.datediff(Full_DataFrame[\"Ship_Date\"],Full_DataFrame[\"Order_Date\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------+------+-------------+-------------------+-------------+--------+------+----------------+---------+----------+--------------+--------+----------------+--------------------+-------+--------+-----------+----------+--------+--------------------+\n",
      "| Sales|Discount|Order_Quantity|Profit|Shipping_Cost|Product_Base_Margin|Customer_Name|Province|Region|Customer_Segment|  Cust_id|Order_Date|Order_Priority|  Ord_id|Product_Category|Product_Sub_Category|Prod_id|Order_ID|  Ship_Mode| Ship_Date| Ship_id|DaysTakenForDelivery|\n",
      "+------+--------+--------------+------+-------------+-------------------+-------------+--------+------+----------------+---------+----------+--------------+--------+----------------+--------------------+-------+--------+-----------+----------+--------+--------------------+\n",
      "|136.81|    0.01|            23|-30.51|          3.6|               0.56|AARON BERGMAN| ALBERTA|  WEST|       CORPORATE|Cust_1818|2010-01-27| NOT SPECIFIED|Ord_5446| OFFICE SUPPLIES|SCISSORS, RULERS ...|Prod_16|   36262|REGULAR AIR|2010-01-28|SHP_7609|                   1|\n",
      "| 42.27|    0.01|            13|  4.56|         0.93|               0.54|AARON BERGMAN| ALBERTA|  WEST|       CORPORATE|Cust_1818|2009-01-07|          HIGH|Ord_5406| OFFICE SUPPLIES| PENS & ART SUPPLIES|Prod_13|   20513|EXPRESS AIR|2009-01-08|SHP_7549|                   1|\n",
      "+------+--------+--------------+------+-------------+-------------------+-------------+--------+------+----------------+---------+----------+--------------+--------+----------------+--------------------+-------+--------+-----------+----------+--------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Full_DataFrame.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Find the customer whose order took the maximum time to get delivered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "| Cust_id|Max_daysTaken|\n",
      "+--------+-------------+\n",
      "|Cust_814|          365|\n",
      "+--------+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Full_DataFrame.groupBy(F.col(\"Cust_id\")).agg(F.max(\"DaysTakenForDelivery\").alias(\"Max_daysTaken\")).orderBy(F.desc(\"Max_daysTaken\")).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Using the windows function, retrieve total sales made by each product from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|Prod_id|       total_sales|\n",
      "+-------+------------------+\n",
      "| Prod_4| 1889313.801999998|\n",
      "| Prod_1|1070182.6000000006|\n",
      "| Prod_7|15006.630000000001|\n",
      "| Prod_8| 795875.9399999998|\n",
      "|Prod_13|167107.21999999997|\n",
      "|Prod_14|1130361.2999999996|\n",
      "|Prod_16| 80996.30999999997|\n",
      "| Prod_2| 736991.5399999997|\n",
      "|Prod_11|1896008.1420000014|\n",
      "|Prod_10| 822652.0400000003|\n",
      "|Prod_17|2168697.1400000006|\n",
      "| Prod_5| 698093.8100000003|\n",
      "|Prod_15|        1761836.55|\n",
      "| Prod_3|1022957.5900000007|\n",
      "|Prod_12| 38981.55000000002|\n",
      "| Prod_6| 446452.8599999995|\n",
      "| Prod_9|174085.80000000008|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "# Define a window specification over the product_id\n",
    "window_spec = Window.partitionBy(\"Prod_id\")\n",
    "\n",
    "# Calculate the total sales made by each product\n",
    "total_sales_by_product = Full_DataFrame.withColumn(\"total_sales\",\n",
    "                                                    F.sum(\"Sales\").over(window_spec))\n",
    "\n",
    "# Select only the required columns\n",
    "total_sales_by_product = total_sales_by_product.select(\"Prod_id\", \"total_sales\").distinct()\n",
    "\n",
    "# Show the total sales made by each product\n",
    "total_sales_by_product.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Using the windows function retrieve the total profit made from each product from the data and also do without the windows function using pyspark data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|Prod_id|      total_profit|\n",
      "+-------+------------------+\n",
      "| Prod_4| 316951.6200000003|\n",
      "| Prod_1| 6664.149999999999|\n",
      "| Prod_7|-102.6700000000001|\n",
      "| Prod_8| 94287.48000000001|\n",
      "|Prod_13| 7564.780000000003|\n",
      "|Prod_14|167361.48999999996|\n",
      "|Prod_16|-7799.250000000001|\n",
      "| Prod_2| 97158.05999999988|\n",
      "|Prod_11|-99062.50000000001|\n",
      "|Prod_10|-33582.13000000002|\n",
      "|Prod_17|307712.92999999993|\n",
      "| Prod_5|         100427.93|\n",
      "|Prod_15|149649.73000000004|\n",
      "| Prod_3|307413.38999999996|\n",
      "|Prod_12| 13677.16999999999|\n",
      "| Prod_6| 45263.20000000003|\n",
      "| Prod_9| 48182.60000000004|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "# Define a window specification over the product_id\n",
    "window_spec = Window.partitionBy(\"Prod_id\")\n",
    "\n",
    "# Calculate the total profit made by each product\n",
    "total_profit_by_product = Full_DataFrame.withColumn(\"total_profit\",\n",
    "                                                    F.sum(\"Profit\").over(window_spec))\n",
    "\n",
    "# Select only the required columns\n",
    "total_profit_by_product = total_profit_by_product.select(\"Prod_id\", \"total_profit\").distinct()\n",
    "\n",
    "# Show the total profit made from each product\n",
    "total_profit_by_product.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 9. Count the total number of unique customers in January and how many of them came back every month over the entire year in 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------+------+-------------+-------------------+-------------+--------+------+----------------+---------+----------+--------------+--------+----------------+--------------------+-------+--------+-----------+----------+--------+--------------------+\n",
      "| Sales|Discount|Order_Quantity|Profit|Shipping_Cost|Product_Base_Margin|Customer_Name|Province|Region|Customer_Segment|  Cust_id|Order_Date|Order_Priority|  Ord_id|Product_Category|Product_Sub_Category|Prod_id|Order_ID|  Ship_Mode| Ship_Date| Ship_id|DaysTakenForDelivery|\n",
      "+------+--------+--------------+------+-------------+-------------------+-------------+--------+------+----------------+---------+----------+--------------+--------+----------------+--------------------+-------+--------+-----------+----------+--------+--------------------+\n",
      "|136.81|    0.01|            23|-30.51|          3.6|               0.56|AARON BERGMAN| ALBERTA|  WEST|       CORPORATE|Cust_1818|2010-01-27| NOT SPECIFIED|Ord_5446| OFFICE SUPPLIES|SCISSORS, RULERS ...|Prod_16|   36262|REGULAR AIR|2010-01-28|SHP_7609|                   1|\n",
      "+------+--------+--------------+------+-------------+-------------------+-------------+--------+------+----------------+---------+----------+--------------+--------+----------------+--------------------+-------+--------+-----------+----------+--------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Full_DataFrame.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique customers in January 2011: 961\n",
      "Month: 1 Returning Customers Count: 961\n",
      "Month: 2 Returning Customers Count: 0\n",
      "Month: 3 Returning Customers Count: 0\n",
      "Month: 4 Returning Customers Count: 0\n",
      "Month: 5 Returning Customers Count: 0\n",
      "Month: 6 Returning Customers Count: 0\n",
      "Month: 7 Returning Customers Count: 0\n",
      "Month: 8 Returning Customers Count: 0\n",
      "Month: 9 Returning Customers Count: 0\n",
      "Month: 10 Returning Customers Count: 0\n",
      "Month: 11 Returning Customers Count: 0\n",
      "Month: 12 Returning Customers Count: 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import month, year, countDistinct\n",
    "\n",
    "# Assuming the DataFrame containing the data is named 'sales_df'\n",
    "\n",
    "# Filter data for January 2011\n",
    "january_data = Full_DataFrame.filter((year(\"Order_Date\") == 2011) & (month(\"Order_Date\") == 1))\n",
    "\n",
    "# Count the total number of unique customers in January\n",
    "january_unique_customers_count = january_data.select(countDistinct(\"Cust_id\")).collect()[0][0]\n",
    "\n",
    "# Create an array to store the number of returning customers for each month\n",
    "returning_customers_counts = []\n",
    "\n",
    "# Iterate over each month in 2011\n",
    "for month_num in range(1, 13):\n",
    "    # Filter data for the current month\n",
    "    month_data = Full_DataFrame.filter((year(\"Order_Date\") == 2011) & (month(\"Order_Date\") == month_num))\n",
    "    \n",
    "    # Count the total number of unique customers for the current month\n",
    "    unique_customers_count = month_data.select(countDistinct(\"Cust_id\")).collect()[0][0]\n",
    "    \n",
    "    # Filter data for customers who appeared in January\n",
    "    january_customer_ids = january_data.select(\"Cust_id\").collect()\n",
    "    returning_customers_count = month_data.filter(month_data[\"Cust_id\"].isin([row.Cust_id for row in january_customer_ids])).select(countDistinct(\"Cust_id\")).collect()[0][0]\n",
    "    \n",
    "    returning_customers_counts.append((month_num, returning_customers_count))\n",
    "\n",
    "# Show the total number of unique customers in January\n",
    "print(\"Total number of unique customers in January 2011:\", january_unique_customers_count)\n",
    "\n",
    "# Show how many of them came back every month over the entire year in 2011\n",
    "for month_num, returning_customers_count in returning_customers_counts:\n",
    "    print(\"Month:\", month_num, \"Returning Customers Count:\", returning_customers_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Calculate the total quantity purchased, discount received by the customer, and calculate the total sales sold and profit earned from each customer. Order the datacframe on Total_profit in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------+-----------------------+------------------+-------------------+\n",
      "|  Cust_id|Total_Quantity_Purchased|Total_Discount_Received|  Total_Sales_Sold|Total_Profit_Earned|\n",
      "+---------+------------------------+-----------------------+------------------+-------------------+\n",
      "|Cust_1151|                     129|                    0.4|         97011.194|           28663.71|\n",
      "|  Cust_63|                     242|    0.29000000000000004|        54368.9085| 20877.440000000002|\n",
      "|Cust_1571|                     112|    0.22000000000000003|         47445.573|           19439.52|\n",
      "|Cust_1421|                     434|                   0.71|         67285.132|           18960.63|\n",
      "| Cust_937|                     130|                   0.33| 48660.87300000001|           18849.93|\n",
      "|Cust_1799|                     567|                   0.97| 70426.59000000001| 18760.589999999997|\n",
      "| Cust_934|                     316|     0.6700000000000002|45000.488999999994| 17044.219999999998|\n",
      "|Cust_1748|                     181|                   0.25|          46147.22|           16080.57|\n",
      "|Cust_1307|                     107|                   0.38|          35781.38|           15082.66|\n",
      "|Cust_1310|                     432|     0.5800000000000001| 45458.40700000001| 14712.949999999999|\n",
      "| Cust_997|                     291|    0.42000000000000004|54685.799999999996| 14125.069999999998|\n",
      "|Cust_1170|                      72|                   0.18|        29623.5205|           13041.07|\n",
      "|Cust_1763|                     100|                   0.18|          26812.47|           12552.75|\n",
      "| Cust_466|                     390|     0.7900000000000001|54630.104499999994| 11960.800000000001|\n",
      "|Cust_1746|                     304|     0.8400000000000001|        50378.1595| 11765.159999999996|\n",
      "|Cust_1007|                     410|     0.6399999999999999| 72331.87999999998|           11090.07|\n",
      "| Cust_962|                     200|    0.30000000000000004|          37675.81|           11033.87|\n",
      "|Cust_1143|                     280|                   0.25|          40134.96| 10869.859999999999|\n",
      "|Cust_1793|                     217|                   0.38|46399.437999999995|           10647.93|\n",
      "| Cust_995|                     371|                   0.48|35884.060000000005| 10571.800000000001|\n",
      "+---------+------------------------+-----------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_profit_df = Full_DataFrame.groupBy(\"Cust_id\").agg(\n",
    "    F.sum(\"Order_Quantity\").alias(\"Total_Quantity_Purchased\"),\n",
    "    F.sum(\"Discount\").alias(\"Total_Discount_Received\"),\n",
    "    F.sum(\"Sales\").alias(\"Total_Sales_Sold\"),\n",
    "    F.sum(\"Profit\").alias(\"Total_Profit_Earned\")\n",
    ")\n",
    "\n",
    "# Order the DataFrame on Total_profit in descending order\n",
    "customer_profit_df = customer_profit_df.orderBy(F.col(\"Total_Profit_Earned\").desc())\n",
    "\n",
    "# Show the DataFrame\n",
    "customer_profit_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbconvert in c:\\users\\dell\\anaconda3\\lib\\site-packages (6.4.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: traitlets>=5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (5.1.1)\n",
      "Requirement already satisfied: testpath in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (0.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (2.11.2)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (4.9.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (4.11.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (0.8.4)\n",
      "Requirement already satisfied: bleach in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (4.1.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (0.4)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=2.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (3.1.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (0.5.13)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (0.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (1.5.0)\n",
      "Requirement already satisfied: nbformat>=4.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert) (5.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jinja2>=2.4->nbconvert) (2.0.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (6.1.12)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (1.5.5)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (22.3.0)\n",
      "Requirement already satisfied: tornado>=4.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (2.8.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jupyter-core->nbconvert) (302)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbformat>=4.4->nbconvert) (4.4.0)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbformat>=4.4->nbconvert) (2.15.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (21.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert) (2.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from bleach->nbconvert) (21.3)\n",
      "Requirement already satisfied: webencodings in c:\\users\\dell\\anaconda3\\lib\\site-packages (from bleach->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from packaging->bleach->nbconvert) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1173105302.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [3]\u001b[1;36m\u001b[0m\n\u001b[1;33m    jupyter nbconvert --to pdf MyNotebook.ipynb\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter nbconvert --to pdf MyNotebook.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting notebook-as-pdf\n",
      "  Downloading notebook_as_pdf-0.5.0-py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: pyppeteer in c:\\users\\dell\\anaconda3\\lib\\site-packages (from notebook-as-pdf) (1.0.2)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\dell\\anaconda3\\lib\\site-packages (from notebook-as-pdf) (6.4.4)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (1.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: bleach in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (4.1.0)\n",
      "\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (0.1.2)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (2.11.2)\n",
      "Requirement already satisfied: nbformat>=4.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (5.3.0)\n",
      "Requirement already satisfied: traitlets>=5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (5.1.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (0.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (0.8.4)\n",
      "Requirement already satisfied: jinja2>=2.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (3.1.3)\n",
      "Requirement already satisfied: testpath in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (0.5.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (4.11.1)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (4.9.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbconvert->notebook-as-pdf) (0.5.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jinja2>=2.4->nbconvert->notebook-as-pdf) (2.0.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook-as-pdf) (6.1.12)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook-as-pdf) (1.5.5)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert->notebook-as-pdf) (22.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert->notebook-as-pdf) (2.8.2)\n",
      "Requirement already satisfied: tornado>=4.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert->notebook-as-pdf) (6.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jupyter-core->nbconvert->notebook-as-pdf) (302)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbformat>=4.4->nbconvert->notebook-as-pdf) (4.4.0)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nbformat>=4.4->nbconvert->notebook-as-pdf) (2.15.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->notebook-as-pdf) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->notebook-as-pdf) (21.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert->notebook-as-pdf) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert->notebook-as-pdf) (2.3.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\dell\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook-as-pdf) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook-as-pdf) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from packaging->bleach->nbconvert->notebook-as-pdf) (3.0.4)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from PyPDF2->notebook-as-pdf) (4.1.1)\n",
      "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyppeteer->notebook-as-pdf) (8.2.2)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyppeteer->notebook-as-pdf) (1.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyppeteer->notebook-as-pdf) (4.11.3)\n",
      "Requirement already satisfied: certifi>=2021 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyppeteer->notebook-as-pdf) (2021.10.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyppeteer->notebook-as-pdf) (4.64.0)\n",
      "Requirement already satisfied: websockets<11.0,>=10.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyppeteer->notebook-as-pdf) (10.3)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyppeteer->notebook-as-pdf) (1.26.9)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->pyppeteer->notebook-as-pdf) (3.7.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer->notebook-as-pdf) (0.4.4)\n",
      "Installing collected packages: PyPDF2, notebook-as-pdf\n",
      "Successfully installed PyPDF2-3.0.1 notebook-as-pdf-0.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install notebook-as-pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jupyter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mjupyter\u001b[49m\u001b[38;5;241m-\u001b[39mnbconvert\u001b[38;5;241m-\u001b[39mtoPDFviaHTML\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jupyter' is not defined"
     ]
    }
   ],
   "source": [
    "jupyter-nbconvert-toPDFviaHTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[43mallow\u001b[49m\u001b[38;5;241m-\u001b[39mchromium\u001b[38;5;241m-\u001b[39mdownload\n",
      "\u001b[1;31mNameError\u001b[0m: name 'allow' is not defined"
     ]
    }
   ],
   "source": [
    "--allow-chromium-download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
